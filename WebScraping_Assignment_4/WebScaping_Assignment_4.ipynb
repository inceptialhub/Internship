{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a65412",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa23efaf",
   "metadata": {},
   "source": [
    "### Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "### You need to find following details: A) Rank\n",
    "### B) Name\n",
    "### C) Artist\n",
    "### D) Upload date E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b18e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException,ElementNotVisibleException,ElementClickInterceptedException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver = webdriver.Chrome('/Users/aditya/Downloads/chromedriver')\n",
    "driver.maximize_window()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5f20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "upload_date=[]\n",
    "views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149dfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "try:\n",
    "    for i in rank_tag[0:30]:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append(\"-\")\n",
    "except ElementNotVisibleException:\n",
    "    rank.append(\"--\")\n",
    "    \n",
    "name_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for i in name_tag[0:30]:\n",
    "        v_name=i.text.split('[')\n",
    "        name.append(v_name[0])\n",
    "except NoSuchElementException:\n",
    "    name.append(\"-\")\n",
    "except ElementNotVisibleException:\n",
    "    name.append(\"--\")\n",
    "    \n",
    "artist_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for i in artist_tag[0:30]:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    artist.append(\"-\")\n",
    "    \n",
    "date_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')\n",
    "try:\n",
    "    for i in date_tag[0:30]:\n",
    "        upload_date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    upload_date.append(\"-\")\n",
    "    \n",
    "view_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "try:\n",
    "    for i in view_tag[0:30]:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    views.append(\"-\")\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b745b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed=pd.DataFrame({'Rank':rank,'Video Name':name,'Artist':artist,'Upload Date':upload_date,'Views':views})\n",
    "most_viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ff1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv.\n",
    "# Url = https://www.bcci.tv/.\n",
    "\n",
    "# You need to find following details:\n",
    "\n",
    "# A) Match title (I.e. 1st ODI)\n",
    "\n",
    "# B) Series\n",
    "\n",
    "# C) Place\n",
    "\n",
    "# D) Date\n",
    "\n",
    "# E) Time\n",
    "\n",
    "# Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb359539",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bcci.tv'\n",
    "driver = webdriver.Chrome('/Users/aditya/Downloads/chromedriver')\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "\n",
    "match_title=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "m_time=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#Click on INTERNATIONAL navigation\n",
    "driver.find_element(By.XPATH,\"//a[normalize-space()='INTERNATIONAL']\").click()\n",
    "\n",
    "time.sleep(3)\n",
    "for _ in range(1):\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'/html[1]/body[1]/div[2]/div[2]/div[1]/div[1]/div[1]/div[2]/div[3]/div[2]/div[1]/button[1]').click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"NoSuchElementException \")\n",
    "    \n",
    "title_tag=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "try:\n",
    "    for i in title_tag:\n",
    "        match_title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    match_title.append(\"-\")\n",
    "match_title\n",
    "\n",
    "\n",
    "series_tag=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "try:\n",
    "    for i in series_tag:\n",
    "        s_tag=i.text.split('-')\n",
    "        series.append(s_tag[0])\n",
    "except NoSuchElementException:\n",
    "    series.append(\"-\")\n",
    "    \n",
    "\n",
    "place_tag=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "try:\n",
    "    for i in place_tag:\n",
    "        p_tag=i.text.split('-')\n",
    "        place.append(p_tag[1])\n",
    "except NoSuchElementException:\n",
    "    place.append(\"-\")\n",
    "    \n",
    "\n",
    "\n",
    "date_tag=driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "try:\n",
    "    for i in date_tag:\n",
    "        date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    date.append(\"-\")\n",
    "    \n",
    "\n",
    "time_tag=driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "try:\n",
    "    for i in time_tag:\n",
    "        m_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    m_time.append(\"-\")\n",
    "    \n",
    "driver.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e5cb778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>1st Test</td>\n",
       "      <td>Vidarbha Cricket Association Stadium, Nagpur</td>\n",
       "      <td>9 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>12 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>15 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>2nd Test</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>17 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>18 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>4th T20I</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>20 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>3rd Test</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,...</td>\n",
       "      <td>1 MAR 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>9 MAR 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>17 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA</td>\n",
       "      <td>19 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>MA Chidambaram Stadium, Chennai</td>\n",
       "      <td>22 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Match Title     Series  \\\n",
       "0   AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23  1st Test    \n",
       "1                 ICC WOMENS T20 WORLD CUP 2023  1st T20I    \n",
       "2                 ICC WOMENS T20 WORLD CUP 2023  2nd T20I    \n",
       "3   AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23  2nd Test    \n",
       "4                 ICC WOMENS T20 WORLD CUP 2023  3rd T20I    \n",
       "5                 ICC WOMENS T20 WORLD CUP 2023  4th T20I    \n",
       "6   AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23  3rd Test    \n",
       "7   AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23  4th Test    \n",
       "8    AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23   1st ODI    \n",
       "9    AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23   2nd ODI    \n",
       "10   AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23   3rd ODI    \n",
       "\n",
       "                                                Place         Date  \\\n",
       "0        Vidarbha Cricket Association Stadium, Nagpur   9 FEB 2023   \n",
       "1                                 Newlands, Cape Town  12 FEB 2023   \n",
       "2                                 Newlands, Cape Town  15 FEB 2023   \n",
       "3                         Arun Jaitley Stadium, Delhi  17 FEB 2023   \n",
       "4                          St George's Park, Gqeberha  18 FEB 2023   \n",
       "5                          St George's Park, Gqeberha  20 FEB 2023   \n",
       "6    Himachal Pradesh Cricket Association Stadium,...   1 MAR 2023   \n",
       "7                    Narendra Modi Stadium, Ahmedabad   9 MAR 2023   \n",
       "8                            Wankhede Stadium, Mumbai  17 MAR 2023   \n",
       "9                         Dr YS Rajasekhara Reddy ACA  19 MAR 2023   \n",
       "10                    MA Chidambaram Stadium, Chennai  22 MAR 2023   \n",
       "\n",
       "           Time  \n",
       "0   9:30 AM IST  \n",
       "1   6:30 PM IST  \n",
       "2   6:30 PM IST  \n",
       "3   9:30 AM IST  \n",
       "4   6:30 PM IST  \n",
       "5   6:30 PM IST  \n",
       "6   9:30 AM IST  \n",
       "7   9:30 AM IST  \n",
       "8   1:30 PM IST  \n",
       "9   1:30 PM IST  \n",
       "10  1:30 PM IST  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "international_fixtures=pd.DataFrame({'Match Title':match_title,'Series':series,'Place':place,'Date':date,'Time':m_time})\n",
    "international_fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dce41c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(international_fixtures))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c99cce1",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1de415f",
   "metadata": {},
   "source": [
    " Url = https://github.com/\n",
    " You have to find the following details:\n",
    " A) Repository title\n",
    " B) Repository description \n",
    " C) Contributors count\n",
    " D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e859fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/Users/aditya/Downloads/chromedriver')\n",
    "driver.maximize_window()\n",
    "url=\"https://github.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ad115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on explore sub menu\n",
    "explore = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[1]/button')\n",
    "try:\n",
    "    explore.click()\n",
    "    time.sleep(5)\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(explore.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2082911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on Trending under explore sub menu\n",
    "trending = driver.find_element(By.XPATH,'//*[@href=\"/trending\"]')\n",
    "try:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_title= []\n",
    "Repository_description= []\n",
    "Contributors_count= []\n",
    "Language_used= []\n",
    "urls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3199fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping title of repository\n",
    "try:\n",
    "    Repository_title_tag=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/h1/a')\n",
    "    for i in Repository_title_tag:\n",
    "        Repository_title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Repository_title.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Scraping description of Repository\n",
    "try:\n",
    "    description=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/p')\n",
    "    for i in description:\n",
    "        Repository_description.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Repository_description.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f71952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in [Repository_title_tag,description]:\n",
    "    for j in i:\n",
    "        if i ==Repository_title_tag:\n",
    "            Repository_title.append(j.text)\n",
    "            urls.append(j.get_attribute('href'))\n",
    "        if i==description:\n",
    "            Repository_description.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6068dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    div_list=driver.find_elements(By.XPATH,'//div[@class=\"BorderGrid BorderGrid--spacious\"]/div')\n",
    "    #Scraping count of contributors   \n",
    "    try:\n",
    "        Contributors_count.append(((div_list[-2].text).split())[1])\n",
    "    except:\n",
    "        Contributors_count.append('-')\n",
    "    #Scraping used language\n",
    "    try:\n",
    "        Language_used.append(((div_list[-1].text).split())[1::2])\n",
    "    except:\n",
    "        Language_used.append('-')\n",
    "        \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aff640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Dataframe\n",
    "github_trending=pd.DataFrame({\"Repository_title\":Repository_title[:25],\"Repository_description\":Repository_description[:25],\"Language_used\":Language_used[:25],\"Contributors_count\":Contributors_count[:25]})\n",
    "github_trending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cae2b1",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5dc863d",
   "metadata": {},
   "source": [
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250d81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6849f62f",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey- compare/\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba6a43bd",
   "metadata": {},
   "source": [
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name \n",
    "C) Volumes sold \n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3166458",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name=[]\n",
    "author_name=[]\n",
    "volumes_sold=[]\n",
    "publisher=[]\n",
    "genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c836dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_name=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[2]')\n",
    "try:\n",
    "    for i in b_name:\n",
    "        book_name.append(i.text)\n",
    "except:\n",
    "    book_name.append(\"-\")\n",
    "    \n",
    "a_name=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[3]')\n",
    "try:\n",
    "    for i in a_name:\n",
    "        author_name.append(i.text)\n",
    "except:\n",
    "    author_name.append(\"-\")\n",
    "    \n",
    "v_sold=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[4]')\n",
    "try:\n",
    "    for i in v_sold:\n",
    "        volumes_sold.append(i.text)\n",
    "except:\n",
    "    volumes_sold.append(\"-\")\n",
    "    \n",
    "b_publisher=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[5]')\n",
    "try:\n",
    "    for i in b_publisher:\n",
    "        publisher.append(i.text)\n",
    "except:\n",
    "    publisher.append(\"-\")\n",
    "    \n",
    "b_genre=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[6]')\n",
    "try:\n",
    "    for i in b_genre:\n",
    "        genre.append(i.text)\n",
    "except:\n",
    "    genre.append(\"-\")\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f4334",
   "metadata": {},
   "outputs": [],
   "source": [
    "Highest_selling_novels=pd.DataFrame({'Book Name':book_name,'Author Name':author_name,'Volumes sold':volumes_sold,'Publisher':publisher,'Genre':genre})\n",
    "Highest_selling_novels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa6b94",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff792a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "url='https://www.imdb.com/list/ls095964455'\n",
    "driver.get(url)\n",
    "\n",
    "name=[]\n",
    "year=[]\n",
    "genre=[]\n",
    "run_time=[]\n",
    "ratings=[]\n",
    "votes=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_name=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "try:\n",
    "    for i in s_name:\n",
    "        name.append(i.text)\n",
    "except:\n",
    "    name.append(\"--\") \n",
    "    \n",
    "s_year=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "try:\n",
    "    for i in s_year:\n",
    "        year.append(i.text)\n",
    "except:\n",
    "    year.append(\"--\")   \n",
    "\n",
    "s_genre=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[5]')\n",
    "try:\n",
    "    for i in s_genre:\n",
    "        genre.append(i.text)\n",
    "except:\n",
    "    genre.append(\"--\")\n",
    "    \n",
    "r_time=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[3]')\n",
    "try:\n",
    "    for i in r_time:\n",
    "        run_time.append(i.text)\n",
    "except:\n",
    "    run_time.append(\"--\")   \n",
    "\n",
    "rating=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]/div/span[2]')\n",
    "try:\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "except:\n",
    "    ratings.append(\"--\")\n",
    "    \n",
    "vote=driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "try:\n",
    "    for i in vote:\n",
    "        votes.append(i.text)\n",
    "except:\n",
    "    votes.append(\"--\")\n",
    "    \n",
    "driver.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c325fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_series=pd.DataFrame({'Name':name,'Year Span':year,'Genre':genre,'Run Time':run_time,'Ratings':ratings,'Votes':votes})\n",
    "tv_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33011e2d",
   "metadata": {},
   "source": [
    "# 8 Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3df21fc7",
   "metadata": {},
   "source": [
    "A) Dataset name B) Data type\n",
    "C) Task\n",
    "D) Attribute type E) No of instances F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "url='https://archive.ics.uci.edu/ml/index.php'\n",
    "driver.get(url)\n",
    "\n",
    "#clicking on view all Dataset\n",
    "Dataset= driver.find_elements(By.XPATH,\"//span[@class='normal']/b/a\")[0].get_attribute('href')\n",
    "driver.get(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a58f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping dataset\n",
    "data=[]\n",
    "try:\n",
    "    data_tag=driver.find_elements(By.XPATH,\"//td//p[@class='normal']\")\n",
    "    for i in data_tag[8:4362]:\n",
    "        data.append(i.text )\n",
    "except:\n",
    "    data.append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing dataset\n",
    "Dataset_name=data[::7]\n",
    "Data_type=data[1::7]\n",
    "Task=data[2::7]\n",
    "Attribute_type=data[3::7]\n",
    "instances=data[4::7]\n",
    "attribute=data[5::7]\n",
    "Year=data[6::7]\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ee005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Dataframe\n",
    "Datasets= pd.DataFrame({\"Dataset name\":Dataset_name,\"Data type\":Data_type,\"Task\":Task,\"Attribute type\":Attribute_type,\"Instances\":instances,\"Attribute\":attribute,\"Year\":Year})\n",
    "Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355ae79",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c479297a",
   "metadata": {},
   "source": [
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc11afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.guru99.com'\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "text='selenium exception handling'\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b96101",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'//span[@class=\"kadence-svg-iconset\"]')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    search_text=driver.find_element(By.XPATH,'//input[@class=\"search-field\"]')\n",
    "    search_text.send_keys('selenium exception handling')\n",
    "except:\n",
    "    print(\"error in entering text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c19a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchButton=driver.find_element(By.XPATH,'//input[@class=\"search-submit\"]')\n",
    "searchButton.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "exception_page=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/div/div/div/div/div/div[5]/div[2]/div/div/div[1]/div[1]/div[1]/div[1]/div/a')\n",
    "exception_page.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145de90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptionName=[]\n",
    "except_tag=driver.find_elements(By.XPATH,'//*[@id=\"post-1953\"]/div/div/p/strong')\n",
    "try:\n",
    "    for i in except_tag[0:41]:\n",
    "        e_tag=i.text.split(\".\")\n",
    "        exceptionName.append(e_tag[1].replace(\":\",\"\"))\n",
    "except NoSuchElementException:\n",
    "    exceptionName.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "description=[]\n",
    "description_tag=driver.find_elements(By.XPATH,'//*[@id=\"post-1953\"]/div/div/p')\n",
    "try:\n",
    "    for i in description_tag[0:41]:\n",
    "        d_text=i.text.split(\":\")\n",
    "        description.append(d_text[1])\n",
    "except NoSuchElementException:\n",
    "    description.append(\"-\")\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d7db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Excecption_details=pd.DataFrame({'Exception Name':exceptionName,'Exception Description':description})\n",
    "Excecption_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec115d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
